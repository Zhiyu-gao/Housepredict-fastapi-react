#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
é“¾å®¶äºŒæ‰‹æˆ¿çˆ¬è™«ï¼ˆCDP + çœŸ Chrome + äººå·¥éªŒè¯å…œåº•ï¼‰
"""

import json
import random
from pathlib import Path
from datetime import datetime
from playwright.sync_api import sync_playwright, TimeoutError as PlaywrightTimeoutError

# ======================
# é…ç½®
# ======================

START_URL = "https://sh.lianjia.com/ershoufang/pudong/"

BASE_DIR = Path(__file__).resolve().parent
OUT_DIR = BASE_DIR / "lianjia_json"
OUT_DIR.mkdir(exist_ok=True)

CDP_ENDPOINT = "http://localhost:9222"

# ======================
# å·¥å…·å‡½æ•°
# ======================

def now_str():
    return datetime.now().strftime("%Y-%m-%d %H:%M:%S")

def safe_filename(text: str, max_len=80):
    if not text:
        return "unknown"
    return "".join(c for c in text if c.isalnum() or c in " _-").strip()[:max_len]

def human_scroll_to_bottom(page, step=300, delay=0.15):
    last_height = page.evaluate("document.body.scrollHeight")
    while True:
        page.evaluate(f"window.scrollBy(0, {step})")
        page.wait_for_timeout(int(delay * 1000))
        new_height = page.evaluate("document.body.scrollHeight")
        scroll_y = page.evaluate("window.scrollY + window.innerHeight")
        if scroll_y >= new_height - 10 or new_height == last_height:
            break
        last_height = new_height

def detect_human_verify(page) -> bool:
    """
    æ£€æµ‹æ˜¯å¦å‡ºç°äººæœºéªŒè¯ç›¸å…³å†…å®¹
    """
    keywords = ["äººæœºéªŒè¯", "å®‰å…¨éªŒè¯", "è¯·å®ŒæˆéªŒè¯", "verify"]
    try:
        body_text = page.inner_text("body")
    except Exception:
        return False

    return any(k in body_text for k in keywords)

# ======================
# è§£æå‡½æ•°
# ======================

def parse_house(li):
    def text(selector):
        el = li.query_selector(selector)
        return el.inner_text().strip() if el else None

    house_id = li.get_attribute("data-lj_action_housedel_id")

    title_el = li.query_selector(".title a")
    title = title_el.inner_text().strip() if title_el else None
    detail_url = title_el.get_attribute("href") if title_el else None

    community_el = li.query_selector(".positionInfo a")
    community_name = community_el.inner_text().strip() if community_el else None
    community_url = community_el.get_attribute("href") if community_el else None

    district_els = li.query_selector_all(".positionInfo a")
    district = district_els[1].inner_text().strip() if len(district_els) > 1 else None

    house_info = text(".houseInfo") or ""
    parts = [p.strip() for p in house_info.split("|")]

    layout = parts[0] if len(parts) > 0 else None

    area_sqm = None
    if len(parts) > 1 and "å¹³ç±³" in parts[1]:
        try:
            area_sqm = float(parts[1].replace("å¹³ç±³", ""))
        except ValueError:
            pass

    orientation = parts[2] if len(parts) > 2 else None
    decoration = parts[3] if len(parts) > 3 else None
    floor = parts[4] if len(parts) > 4 else None

    build_year = None
    if len(parts) > 5 and "å¹´" in parts[5]:
        try:
            build_year = int(parts[5].replace("å¹´", ""))
        except ValueError:
            pass

    building_type = parts[6] if len(parts) > 6 else None

    total_price_text = text(".totalPrice span")
    total_price_wan = float(total_price_text) if total_price_text else None
    total_price_yuan = int(total_price_wan * 10_000) if total_price_wan else None

    unit_price_text = text(".unitPrice span")
    unit_price = (
        int(unit_price_text.replace("å…ƒ/å¹³", "").replace(",", ""))
        if unit_price_text else None
    )

    follow_info = text(".followInfo") or ""
    follow_count = int(follow_info.split("äººå…³æ³¨")[0]) if "äººå…³æ³¨" in follow_info else 0

    tags = [t.inner_text().strip() for t in li.query_selector_all(".tag span")]

    img = li.query_selector("img.lj-lazy")
    cover_image = (
        img.get_attribute("data-original") or img.get_attribute("src")
        if img else None
    )

    return {
        "house_id": house_id,
        "title": title,
        "detail_url": detail_url,
        "community_name": community_name,
        "community_url": community_url,
        "district": district,
        "layout": layout,
        "area_sqm": area_sqm,
        "orientation": orientation,
        "decoration": decoration,
        "floor": floor,
        "build_year": build_year,
        "building_type": building_type,
        "total_price_wan": total_price_wan,
        "total_price_yuan": total_price_yuan,
        "unit_price": unit_price,
        "follow_count": follow_count,
        "tags": tags,
        "cover_image": cover_image,
        "crawl_time": now_str(),
    }

# ======================
# ä¸»æµç¨‹
# ======================

def main():
    print("ğŸ”Œ è¿æ¥çœŸå® Chromeï¼ˆCDPï¼‰â€¦")

    with sync_playwright() as p:
        browser = p.chromium.connect_over_cdp(CDP_ENDPOINT)

        context = browser.contexts[0]
        page = context.new_page()

        page.goto(START_URL, wait_until="domcontentloaded", timeout=60000)

        page_num = 1

        while True:
            print(f"ğŸ“„ ç¬¬ {page_num} é¡µ")

            # ---------- äººæœºéªŒè¯æ£€æµ‹ ----------
            if detect_human_verify(page):
                print("ğŸ§  æ£€æµ‹åˆ°äººæœºéªŒè¯ï¼Œè¯·æ‰‹åŠ¨å¤„ç†ï¼ˆç­‰å¾… 60 ç§’ï¼‰")
                page.wait_for_timeout(60_000)

            try:
                page.wait_for_selector("li.clear.LOGCLICKDATA", timeout=15000)
            except PlaywrightTimeoutError:
                print("âš ï¸ é¡µé¢åŠ è½½å¤±è´¥ï¼Œåœæ­¢")
                break

            items = page.query_selector_all("li.clear.LOGCLICKDATA")
            for li in items:
                data = parse_house(li)
                if not data["house_id"]:
                    continue

                fname = f"{data['house_id']}_{safe_filename(data['title'])}.json"
                out_path = OUT_DIR / fname
                if out_path.exists():
                    continue

                with open(out_path, "w", encoding="utf-8") as f:
                    json.dump(data, f, ensure_ascii=False, indent=2)

            # ---------- ç¿»é¡µå‰è¡Œä¸º ----------
            human_scroll_to_bottom(page)
            page.wait_for_timeout(1000)

            next_btn = page.query_selector('a:has-text("ä¸‹ä¸€é¡µ")')
            if not next_btn:
                print("âœ… å·²åˆ°æœ€åä¸€é¡µ")
                break

            cls = next_btn.get_attribute("class") or ""
            if "disabled" in cls:
                print("âœ… å·²åˆ°æœ€åä¸€é¡µ")
                break

            next_btn.click()
            page.wait_for_timeout(random.randint(2500, 4000))
            page_num += 1

        print(f"ğŸ‰ å®Œæˆï¼Œæ•°æ®åœ¨ {OUT_DIR}")

# ======================
# å…¥å£
# ======================

if __name__ == "__main__":
    main()
